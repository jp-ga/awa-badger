{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79bc26b7-59fa-47a2-9117-a3170534fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from plugins.interfaces.diagnostics import AWAFrameGrabberDiagnostic, ROI\n",
    "\n",
    "# define screen and trim parameters\n",
    "screen = \"DYG5\"\n",
    "magnet_info = yaml.safe_load(open(\"awa_config/awa_drive_magnet_config.yml\"))\n",
    "screen_info = yaml.safe_load(open(\"awa_config/awa_drive_camera_config.yml\"))[screen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd04b86-bed1-4775-9f78-26727da18b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Xopt objects\n",
    "from xopt import VOCS\n",
    "IMAGE_CONSTRAINTS = {\n",
    "            \"bb_penalty\": [\"LESS_THAN\", 0.0],\n",
    "        }\n",
    "\n",
    "vocs = VOCS(\n",
    "    variables = {\n",
    "        \"AWA:Bira3Ctrl:Ch05\":[-1.75,1.75], # DQ6\n",
    "        \"AWA:Drive:DS3:Ctrl\": [130.0,250.0], # Matching solenoid\n",
    "        \"AWA:Drive:DS1:Ctrl\": [450.0,550.0], # Bucking solenoid\n",
    "    },\n",
    "    constraints = IMAGE_CONSTRAINTS,\n",
    "    observables = [\"Sx_squared\", \"Sy_squared\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760e781b-7310-4350-b5d5-61efe22028c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWA:Bira3Ctrl:Ch05', 'AWA:Drive:DS1:Ctrl', 'AWA:Drive:DS3:Ctrl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocs.variable_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb0fac8-61ce-4e1a-8459-7b95c481ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_roi = ROI(\n",
    "    xcenter=int(screen_info[\"center\"][0]),\n",
    "    ycenter=int(screen_info[\"center\"][1]),\n",
    "    xwidth=int(screen_info[\"radius\"]*1.5),\n",
    "    ywidth=int(screen_info[\"radius\"]*1.5),\n",
    ")\n",
    "\n",
    "image_diagnostic = AWAFrameGrabberDiagnostic(\n",
    "    roi=screen_roi, apply_bounding_box_constraint=True, visualize=False,\n",
    "    save_image_location=\"../../awa_data/03_14_BAX/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c09013-50e8-4c40-9e48-4f5e0ef16b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWAFrameGrabberDiagnostic(screen_name='AWANIFrameGrabber', ip_address='N/A', alias=None, array_data_suffix='N/A', array_n_cols_suffix='N/A', array_n_rows_suffix='N/A', resolution_suffix=None, resolution=1.0, beam_shutter_pv=None, extra_pvs=[], background_file=None, save_image_location='../../awa_data/03_14_BAX/', roi=ROI(xcenter=293, ycenter=248, xwidth=310, ywidth=310), gain=1.0, min_log_intensity=4.0, bounding_box_half_width=3.0, wait_time=1.0, n_fitting_restarts=1, visualize=False, verbose=True, return_statistics=False, threshold=0.0, apply_bounding_box_constraint=True, target_charge=None, target_charge_pv=None, charge_atol=0.1, testing=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23811732-3412-4a02-ad81-935f0a656688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from xopt import Evaluator\n",
    "from epics import caput\n",
    "\n",
    "def evaluate(inputs: dict):\n",
    "    global image_diagnostic\n",
    "    # caput values\n",
    "    for name, val in inputs.items():\n",
    "        caput(name, val)\n",
    "\n",
    "    # wait for changes to occur - use small wait time for interpolated measurements\n",
    "    time.sleep(2.0)\n",
    "\n",
    "    results = image_diagnostic.measure_beamsize(1, **inputs)\n",
    "    results[\"Sx_m\"] = results[\"Sx\"] * 25 / screen_info[\"radius\"]\n",
    "    results[\"Sx_squared\"] = results[\"Sx_m\"]**2\n",
    "\n",
    "    results[\"Sy_m\"] = results[\"Sy\"] * 25 / screen_info[\"radius\"]\n",
    "    results[\"Sy_squared\"] = results[\"Sy_m\"]**2\n",
    "    \n",
    "    # measure distance to image center\n",
    "    print(results[\"Cx\"], image_diagnostic.roi.xwidth/2)\n",
    "    results[\"center_dist_x\"] = results[\"Cx\"] - image_diagnostic.roi.xwidth/2\n",
    "    results[\"center_dist_y\"] = results[\"Cy\"] - image_diagnostic.roi.ywidth/2\n",
    "\n",
    "    results[\"center_dist\"] = (results[\"center_dist_x\"]**2 + results[\"center_dist_y\"]**2)**0.5\n",
    "    results[\"time\"] = time.time()\n",
    "    \n",
    "    return results\n",
    "\n",
    "evaluator = Evaluator(function=evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8796688b-3079-45c9-a859-41789f78e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import MaternKernel, PolynomialKernel, ScaleKernel\n",
    "from xopt.generators.bayesian.models.standard import StandardModelConstructor\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "from xopt.generators.bayesian.bayesian_exploration import BayesianExplorationGenerator\n",
    "from copy import deepcopy\n",
    "sys.path.append(\"../../emitopt/\")\n",
    "import torch\n",
    "from emitopt.algorithms import ScipyMinimizeEmittanceXY\n",
    "\n",
    "meas_dim = 0\n",
    "tuning_dims = [1,2]\n",
    "covar_module = (MaternKernel(ard_num_dims=len(tuning_dims), \n",
    "                              active_dims=tuning_dims, \n",
    "                              lengthscale_prior=None) * \n",
    "                              PolynomialKernel(power=2, active_dims=[meas_dim])\n",
    "                 )\n",
    "scaled_covar_module = ScaleKernel(covar_module)   \n",
    "    \n",
    "# prepare options for Xopt generator\n",
    "covar_module_dict = {'Sx_squared': scaled_covar_module, \"Sy_squared\": deepcopy(scaled_covar_module)}\n",
    "# covar_module_dict = {}\n",
    "model_constructor = StandardModelConstructor(\n",
    "    covar_modules=covar_module_dict, use_low_noise_prior=True\n",
    ")\n",
    "\n",
    "from emitopt.utils import get_quad_scale_factor\n",
    "q_len=0.1\n",
    "\n",
    "pv_scale = (q_len*10 / 0.893) # [kG] / [A] for AWA Blue quads\n",
    "geo_scale_factor = get_quad_scale_factor(E=0.060, q_len=q_len) # [m^-2] / [kG] \n",
    "\n",
    "\n",
    "scale_factor = pv_scale * geo_scale_factor\n",
    "rmat_x = torch.tensor(((1.0,2.375),(0.0,1.0)))\n",
    "rmat_y = torch.tensor(((1.0,2.375),(0.0,1.0)))\n",
    "n_samples=10\n",
    "\n",
    "algo_kwargs = {\n",
    "        'x_key': 'Sx_squared',\n",
    "        'y_key': 'Sy_squared',\n",
    "        'scale_factor': scale_factor,\n",
    "        'q_len': q_len,\n",
    "        'rmat_x': rmat_x,\n",
    "        'rmat_y': rmat_y,\n",
    "        'n_samples': n_samples,\n",
    "        'meas_dim': meas_dim,\n",
    "        'n_steps_measurement_param': 11,\n",
    "#         'scipy_options': None,\n",
    "        'thick_quad': False,\n",
    "}\n",
    "algo = ScipyMinimizeEmittanceXY(**algo_kwargs)\n",
    "\n",
    "generator = BaxGenerator(\n",
    "    vocs=vocs, \n",
    "    gp_constructor=model_constructor, \n",
    "    algorithm=algo,\n",
    "    #n_interpolate_points=5,\n",
    ")\n",
    "\n",
    "#generator = BayesianExplorationGenerator(\n",
    "#    vocs=vocs, \n",
    "#    gp_constructor=model_constructor, \n",
    "#)\n",
    "\n",
    "generator.numerical_optimizer.max_time = 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86fdca81-435a-42bf-af84-048357b8d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt import Xopt\n",
    "X = Xopt(vocs=vocs, generator=generator, \n",
    "         evaluator=evaluator, strict=True,dump_file=\"bax_emittance_3d_x_y.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d83af05-86f2-4050-bc81-584b66b2d3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "            Xopt\n",
       "________________________________\n",
       "Version: 2.2.1+8.g7a7eff90.dirty\n",
       "Data size: 0\n",
       "Config as YAML:\n",
       "dump_file: bax_emittance_3d_x_y.yml\n",
       "evaluator:\n",
       "  function: __main__.evaluate\n",
       "  function_kwargs: {}\n",
       "  max_workers: 1\n",
       "  vectorized: false\n",
       "generator:\n",
       "  algorithm:\n",
       "    n_samples: 10\n",
       "  algorithm_results_file: null\n",
       "  computation_time: null\n",
       "  fixed_features: null\n",
       "  gp_constructor:\n",
       "    covar_modules: {}\n",
       "    mean_modules: {}\n",
       "    name: standard\n",
       "    trainable_mean_keys: []\n",
       "    transform_inputs: true\n",
       "    use_low_noise_prior: true\n",
       "  log_transform_acquisition_function: false\n",
       "  max_travel_distances: null\n",
       "  model: null\n",
       "  n_candidates: 1\n",
       "  n_interpolate_points: null\n",
       "  n_monte_carlo_samples: 128\n",
       "  name: BAX\n",
       "  numerical_optimizer:\n",
       "    max_iter: 2000\n",
       "    max_time: 10.0\n",
       "    n_restarts: 20\n",
       "    name: LBFGS\n",
       "  turbo_controller: null\n",
       "  use_cuda: false\n",
       "max_evaluations: null\n",
       "serialize_inline: false\n",
       "serialize_torch: false\n",
       "strict: true\n",
       "vocs:\n",
       "  constants: {}\n",
       "  constraints:\n",
       "    bb_penalty:\n",
       "    - LESS_THAN\n",
       "    - 0.0\n",
       "  objectives: {}\n",
       "  observables:\n",
       "  - Sx_squared\n",
       "  - Sy_squared\n",
       "  variables:\n",
       "    AWA:Bira3Ctrl:Ch05:\n",
       "    - -1.75\n",
       "    - 1.75\n",
       "    AWA:Drive:DS1:Ctrl:\n",
       "    - 450.0\n",
       "    - 550.0\n",
       "    AWA:Drive:DS3:Ctrl:\n",
       "    - 130.0\n",
       "    - 250.0\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5bd26f4-05a4-4191-b00f-89e48afde751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AWA:Bira3Ctrl:Ch05': 0.79622, 'AWA:Drive:DS1:Ctrl': 550.0, 'AWA:Drive:DS3:Ctrl': 141.70598638723578}\n",
      "3\n",
      "fitting image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CA.Client.Exception...............................................\n",
      "    Warning: \"Identical process variable names on multiple servers\"\n",
      "    Context: \"Channel: \"AWANIFG:ImgData\", Connecting to: 192.168.2.57:62521, Ignored: 192.168.0.2:62521\"\n",
      "    Source File: ../cac.cpp line 1320\n",
      "    Current Time: Fri Mar 15 2024 16:53:12.206118528\n",
      "..................................................................\n",
      "CA.Client.Exception...............................................\n",
      "    Warning: \"Identical process variable names on multiple servers\"\n",
      "    Context: \"Channel: \"AWANIFG:ImgData\", Connecting to: 192.168.2.57:62521, Ignored: awa3.hep.anl.gov:62521\"\n",
      "    Source File: ../cac.cpp line 1320\n",
      "    Current Time: Fri Mar 15 2024 16:53:12.207083101\n",
      "..................................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.41267472110175 155.0\n",
      "fitting image\n",
      "152.93948966762315 155.0\n",
      "fitting image\n",
      "153.18401719521594 155.0\n",
      "fitting image\n",
      "139.675429718798 155.0\n",
      "fitting image\n",
      "135.96108913259798 155.0\n",
      "fitting image\n",
      "132.78168986295245 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "115.84708667649255 155.0\n",
      "fitting image\n",
      "158.2472229158813 155.0\n",
      "fitting image\n",
      "158.95231377906225 155.0\n",
      "fitting image\n",
      "160.54136082688956 155.0\n",
      "fitting image\n",
      "144.5775053158504 155.0\n",
      "fitting image\n",
      "145.1490089578104 155.0\n",
      "fitting image\n",
      "150.24493135289424 155.0\n",
      "fitting image\n",
      "127.23339248632932 155.0\n",
      "fitting image\n",
      "133.46121771870733 155.0\n",
      "fitting image\n",
      "132.9873803669633 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n",
      "fitting image\n",
      "nan 155.0\n"
     ]
    }
   ],
   "source": [
    "from epics import caget_many\n",
    "from xopt.utils import get_local_region\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "current_value = dict(zip(X.vocs.variable_names, caget_many(X.vocs.variable_names)))\n",
    "print(current_value)\n",
    "\n",
    "# create a mesh\n",
    "n_samples = 3\n",
    "xx = np.meshgrid(\n",
    "    np.linspace(-0.5, 0.5,n_samples),\n",
    "    np.linspace(130.0, 250.0,n_samples),\n",
    "    np.linspace(500.0, 550.0,n_samples)\n",
    "\n",
    ")\n",
    "pts = np.vstack([ele.flatten() for ele in xx])\n",
    "print(len(pts))\n",
    "\n",
    "import yaml\n",
    "#with open(\"bax_scan_smaller_range.yml\") as stream:\n",
    "#    d =yaml.safe_load(stream)\n",
    "#X.add_data(pd.DataFrame(d['data']))\n",
    "\n",
    "\n",
    "X.evaluate_data({\n",
    "    \"AWA:Bira3Ctrl:Ch05\":pts[0],\n",
    "    \"AWA:Drive:DS3:Ctrl\":pts[1],\n",
    "    \"AWA:Drive:DS1:Ctrl\":pts[2],\n",
    "\n",
    "});\n",
    "#import yaml\n",
    "#X.random_evaluate(2)#, custom_bounds=random_sample_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd26b26c-1407-4435-a547-a3d70702c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/home/awa/awa-badger/control_notebooks/../../emitopt/emitopt/sampling.py:117: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
      "L = torch.cholesky(A)\n",
      "should be replaced with\n",
      "L = torch.linalg.cholesky(A)\n",
      "and\n",
      "U = torch.cholesky(A, upper=True)\n",
      "should be replaced with\n",
      "U = torch.linalg.cholesky(A).mH().\n",
      "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1691.)\n",
      "  Lnn = torch.cholesky(K.to_dense())\n",
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  warnings.warn(first_warn_msg, RuntimeWarning)\n",
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "195.23285368599127 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "128.9027919083571 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "174.34118318607696 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "196.5854654351414 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "170.7224204295187 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "nan 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "195.83050914852842 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "119.25730934854379 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "168.09465585049543 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "196.84967760475223 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "169.17565944996198 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "167.06116633093316 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "113.21775814032895 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "164.62239835609145 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "102.43308105787285 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "104.55387114647571 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "101.51001868937756 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "95.06133185381783 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "146.20615157695096 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "103.15550260580636 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "106.32409874419582 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "94.16689731626664 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "104.17973128717387 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "196.43994723948182 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "149.8976804569289 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "110.43753847078968 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "154.6044958265254 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "94.87871347593831 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "154.28452564447522 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "89.95664236096643 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "115.83799989457432 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "103.67106140925299 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "161.6117505059952 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "99.81261534615567 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "105.00615306067854 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "158.33104881648393 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "97.13647776297029 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "160.3856969541021 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "100.30939673610034 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awa/miniconda3/envs/awa-badger/lib/python3.9/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting image\n",
      "172.1807627437067 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CA.Client.Exception...............................................\n",
      "    Warning: \"Virtual circuit unresponsive\"\n",
      "    Context: \"192.168.0.166:5064\"\n",
      "    Source File: ../tcpiiu.cpp line 926\n",
      "    Current Time: Fri Mar 15 2024 17:14:59.520054805\n",
      "..................................................................\n",
      "Unexpected problem with CA circuit to server \"192.168.0.166:5064\" was \"No route to host\" - disconnecting\n",
      "CA.Client.Exception...............................................\n",
      "    Warning: \"Virtual circuit disconnect\"\n",
      "    Context: \"192.168.0.166:5064\"\n",
      "    Source File: ../cac.cpp line 1237\n",
      "    Current Time: Fri Mar 15 2024 17:30:25.956280034\n",
      "..................................................................\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    X.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c31aaa-9216-4dd8-808c-85a7522560eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.visualize import visualize_generator_model\n",
    "X.generator.train_model()\n",
    "fig,ax = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch05\",\"AWA:Drive:DS3:Ctrl\"],\n",
    "    output_names=[\"Sx_squared\"],\n",
    ")\n",
    "\n",
    "fig,ax = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch05\",\"AWA:Drive:DS1:Ctrl\"],\n",
    "    output_names=[\"Sx_squared\"],\n",
    ")\n",
    "\n",
    "#X_stars = X.generator.algorithm_results[\"X_stars\"]\n",
    "#for ele in X_stars:\n",
    "#    ax[0,0].axhline(ele,c=\"C3\", xmax=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746bade-921d-4284-9f28-efadebf21322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch05\"],\n",
    "    output_names=[\"Sx_squared\"],\n",
    "    reference_point={\"AWA:Drive:DS3:Ctrl\":180.0,\"AWA:Drive:DS1:Ctrl\":525.0},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a215139-93a8-4da3-a0b3-85e08d857701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.visualize import visualize_generator_model\n",
    "X.generator.train_model()\n",
    "fig,ax = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch05\",\"AWA:Drive:DS3:Ctrl\"],\n",
    "    output_names=[\"Sx_squared\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40d5f9-3f0c-4902-92ad-a69f6313918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.plot_utils import plot_virtual_emittance_vs_tuning,plot_pathwise_emittance_vs_tuning\n",
    "X.generator.algorithm.thick_quad = False\n",
    "plot_virtual_emittance_vs_tuning(X, torch.tensor([[525.,170.0]]),n_points=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c74f74-eeb8-4624-bb2e-e4e66ee0d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.plot_utils import plot_virtual_measurement_scan\n",
    "plot_virtual_measurement_scan(X, torch.tensor([[220.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6fa74-fe4d-4a78-9502-63b7a02c8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.visualize import visualize_generator_model\n",
    "\n",
    "fig,ax = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch03\"],\n",
    "    reference_point={\"AWA:Drive:DT8H_B_S:Ctrl\":0.25},\n",
    "    output_names=[\"Cx\"]\n",
    ")\n",
    "\n",
    "fig2,ax2 = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch03\"],\n",
    "    reference_point={\"AWA:Drive:DT8H_B_S:Ctrl\":1.0},\n",
    "    output_names=[\"Cx\"]\n",
    ")\n",
    "\n",
    "fig3,ax3 = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch03\"],\n",
    "    reference_point={\"AWA:Drive:DT8H_B_S:Ctrl\":1.1},\n",
    "    output_names=[\"Cx\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027760c-17e3-4610-a054-6d0ea6788b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.visualize import visualize_generator_model\n",
    "X.generator.train_model()\n",
    "fig,ax = visualize_generator_model(\n",
    "    X.generator, \n",
    "    variable_names=[\"AWA:Bira3Ctrl:Ch03\",\"AWA:Drive:DT8H_B_S:Ctrl\"],\n",
    "    output_names=[\"Cx\"]\n",
    ")\n",
    "#X_stars = X.generator.algorithm_results[\"X_stars\"]\n",
    "#for ele in X_stars:\n",
    "#    ax[0,0].axhline(ele,c=\"C3\", xmax=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f981764-3c84-475c-bb69-3ffd0bf653ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"bax_scan_1.yml\") as stream:\n",
    "    d =yaml.safe_load(stream)\n",
    "import pandas as pd\n",
    "import torch\n",
    "df =pd.DataFrame(d['data'])\n",
    "df\n",
    "\n",
    "df2 =df[df['AWA:Drive:DS3:Ctrl'] == 230.]\n",
    "df2\n",
    "df3 =df2.dropna()\n",
    "df3\n",
    "\n",
    "x = torch.tensor(df3['AWA:Bira3Ctrl:Ch03'])\n",
    "y = torch.tensor(df3['Sx_squared'])\n",
    "\n",
    "from emitopt.utils import get_quad_scale_factor\n",
    "q_len = 0.1\n",
    "pv_scale = (q_len*10 / 0.893) # [kG] / [A] for AWA Blue quads\n",
    "geo_scale_factor = get_quad_scale_factor(E=0.060, q_len=q_len) # [m^-=2] / [kG]\n",
    "\n",
    "scale_factor =pv_scale * geo_scale_factor\n",
    "k =scale_factor * x\n",
    "k\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(k, y)\n",
    "plt.figure()\n",
    "\n",
    "from emitopt.analysis import compute_emit_bmag, compute_emit_bayesian\n",
    "rmat_x =torch.tensor(((1.0,2.375),(0.0,1.0)))\n",
    "#emit = compute_emit_bmag(k, y, q_len, rmat_x)[0]\n",
    "emit =compute_emit_bayesian(\n",
    "    k, y.sqrt(), q_len, \n",
    "    rmat_x,visualize=True,noise_prior=GammaPrior(1.0, 10.0))[0]\n",
    "plt.hist(emit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1d093-844e-44d2-b761-2912e5256bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tuning =  torch.tensor([[220.]])\n",
    "n_samples = 100\n",
    "\n",
    "bax_model_ids = [\n",
    "    X.generator.vocs.output_names.index(name)\n",
    "    for name in X.generator.algorithm.observable_names_ordered\n",
    "]\n",
    "bax_model = X.generator.model.subset_output(bax_model_ids)\n",
    "\n",
    "x = X.generator.algorithm.get_meas_scan_inputs(x_tuning, X.generator.vocs.bounds) # result shape n_tuning_configs*n_steps x ndim\n",
    "\n",
    "p = bax_model.posterior(x)\n",
    "bss = p.sample(torch.Size([n_samples])) # result shape n_samples x n_tuning_configs*n_steps x num_outputs (1 or 2)\n",
    "\n",
    "x = x.reshape(x_tuning.shape[0], X.generator.algorithm.n_steps_measurement_param, -1) # result n_tuning_configs x n_steps x ndim\n",
    "x = x.repeat(n_samples,1,1,1)\n",
    "# result shape n_samples x n_tuning_configs x n_steps x ndim\n",
    "bss = bss.reshape(n_samples, x_tuning.shape[0], X.generator.algorithm.n_steps_measurement_param, -1)\n",
    "# result shape n_samples x n_tuning_configs x n_steps x num_outputs (1 or 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c6780-831d-427e-a145-5abd971b0cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from emitopt.analysis import compute_emit_bmag, compute_emit_bayesian\n",
    "\n",
    "for i in range(40):\n",
    "    plt.plot(x[i,0,:,0],bss[i,0,:,0],'C0')\n",
    "    emit = compute_emit_bmag(\n",
    "        scale_factor *x[i,0,:,0],bss[i,0,:,0], q_len, rmat_x,thick=False\n",
    "    )[0]\n",
    "    print(emit)\n",
    "\n",
    "plt.ylim(-0.75,14)\n",
    "plt.xlim(-0.8,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc39d33-ef79-4b3d-b40f-c6b7832e4e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
